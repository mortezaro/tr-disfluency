{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a70a1-ff36-46d1-94ca-274e6aff595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd702693-fac2-40ed-938f-fe89bd11dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/engs2263/anaconda3/mor/bert_crf-master/bert_crf-master/bert-crf4NER\n"
     ]
    }
   ],
   "source": [
    "%cd bert-crfdisf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08efe457-ec09-40df-8714-83df4618d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-crf==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f5bec-826f-4a53-b919-785d03c3b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176e2f56-aa00-4b76-b0c6-3b0c138b991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-09 17:26:18.414513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-09 17:26:18.414537: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]/home/engs2263/anaconda3/envs/tf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "2021-11-09 17:26:28.585426 Step: 1 of 5656 Loss: 2.338128\n",
      "2021-11-09 17:26:33.979238 Step: 100 of 5656 Loss: 0.045445\n",
      "2021-11-09 17:26:39.823534 Step: 200 of 5656 Loss: 0.018760\n",
      "2021-11-09 17:26:46.046003 Step: 300 of 5656 Loss: 0.014273\n",
      "2021-11-09 17:26:52.300070 Step: 400 of 5656 Loss: 0.016731\n",
      "2021-11-09 17:26:58.633032 Step: 500 of 5656 Loss: 0.015832\n",
      "2021-11-09 17:27:04.852037 Step: 600 of 5656 Loss: 0.014917\n",
      "2021-11-09 17:27:11.104612 Step: 700 of 5656 Loss: 0.014468\n",
      "2021-11-09 17:27:17.389694 Step: 800 of 5656 Loss: 0.012680\n",
      "2021-11-09 17:27:23.576209 Step: 900 of 5656 Loss: 0.011378\n",
      "2021-11-09 17:27:29.934574 Step: 1000 of 5656 Loss: 0.013618\n",
      "2021-11-09 17:27:36.116935 Step: 1100 of 5656 Loss: 0.010983\n",
      "2021-11-09 17:27:41.958407 Step: 1200 of 5656 Loss: 0.012625\n",
      "2021-11-09 17:27:47.779518 Step: 1300 of 5656 Loss: 0.010624\n",
      "2021-11-09 17:27:53.882491 Step: 1400 of 5656 Loss: 0.011053\n",
      "2021-11-09 17:28:00.030234 Step: 1500 of 5656 Loss: 0.011061\n",
      "2021-11-09 17:28:06.278544 Step: 1600 of 5656 Loss: 0.011779\n",
      "2021-11-09 17:28:12.643375 Step: 1700 of 5656 Loss: 0.011321\n",
      "2021-11-09 17:28:18.905807 Step: 1800 of 5656 Loss: 0.010536\n",
      "2021-11-09 17:28:25.215956 Step: 1900 of 5656 Loss: 0.010673\n",
      "2021-11-09 17:28:31.279794 Step: 2000 of 5656 Loss: 0.011567\n",
      "2021-11-09 17:28:37.555584 Step: 2100 of 5656 Loss: 0.011097\n",
      "2021-11-09 17:28:43.364743 Step: 2200 of 5656 Loss: 0.010866\n",
      "2021-11-09 17:28:49.814281 Step: 2300 of 5656 Loss: 0.012114\n",
      "2021-11-09 17:28:55.753143 Step: 2400 of 5656 Loss: 0.009046\n",
      "2021-11-09 17:29:01.610657 Step: 2500 of 5656 Loss: 0.011708\n",
      "2021-11-09 17:29:08.076957 Step: 2600 of 5656 Loss: 0.011108\n",
      "2021-11-09 17:29:14.444753 Step: 2700 of 5656 Loss: 0.011529\n",
      "2021-11-09 17:29:20.677624 Step: 2800 of 5656 Loss: 0.011549\n",
      "2021-11-09 17:29:26.981384 Step: 2900 of 5656 Loss: 0.010300\n",
      "2021-11-09 17:29:33.315418 Step: 3000 of 5656 Loss: 0.011195\n",
      "2021-11-09 17:29:39.596581 Step: 3100 of 5656 Loss: 0.010908\n",
      "2021-11-09 17:29:45.026242 Step: 3200 of 5656 Loss: 0.010813\n",
      "2021-11-09 17:29:51.016733 Step: 3300 of 5656 Loss: 0.011584\n",
      "2021-11-09 17:29:57.262592 Step: 3400 of 5656 Loss: 0.009974\n",
      "2021-11-09 17:30:02.796158 Step: 3500 of 5656 Loss: 0.010683\n",
      "2021-11-09 17:30:09.107963 Step: 3600 of 5656 Loss: 0.010174\n",
      "2021-11-09 17:30:15.378538 Step: 3700 of 5656 Loss: 0.008476\n",
      "2021-11-09 17:30:21.653129 Step: 3800 of 5656 Loss: 0.009239\n",
      "2021-11-09 17:30:27.996926 Step: 3900 of 5656 Loss: 0.008449\n",
      "2021-11-09 17:30:34.209293 Step: 4000 of 5656 Loss: 0.009662\n",
      "2021-11-09 17:30:40.453982 Step: 4100 of 5656 Loss: 0.010428\n",
      "2021-11-09 17:30:46.981910 Step: 4200 of 5656 Loss: 0.010800\n",
      "2021-11-09 17:30:52.864327 Step: 4300 of 5656 Loss: 0.009796\n",
      "2021-11-09 17:30:59.072645 Step: 4400 of 5656 Loss: 0.011092\n",
      "2021-11-09 17:31:04.552787 Step: 4500 of 5656 Loss: 0.009161\n",
      "2021-11-09 17:31:09.979392 Step: 4600 of 5656 Loss: 0.009302\n",
      "2021-11-09 17:31:16.197698 Step: 4700 of 5656 Loss: 0.008988\n",
      "2021-11-09 17:31:22.414591 Step: 4800 of 5656 Loss: 0.008862\n",
      "2021-11-09 17:31:28.770294 Step: 4900 of 5656 Loss: 0.009768\n",
      "2021-11-09 17:31:34.787959 Step: 5000 of 5656 Loss: 0.008692\n",
      "2021-11-09 17:31:40.917864 Step: 5100 of 5656 Loss: 0.010789\n",
      "2021-11-09 17:31:46.913728 Step: 5200 of 5656 Loss: 0.011077\n",
      "2021-11-09 17:31:53.270465 Step: 5300 of 5656 Loss: 0.010766\n",
      "2021-11-09 17:31:59.600622 Step: 5400 of 5656 Loss: 0.009936\n",
      "2021-11-09 17:32:06.096382 Step: 5500 of 5656 Loss: 0.009788\n",
      "2021-11-09 17:32:12.494903 Step: 5600 of 5656 Loss: 0.009634\n",
      "Training Loss: 0.117615 for epoch 0\n",
      "Epoch:  0\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50300.\n",
      "accuracy:  95.40%; (non-O)\n",
      "accuracy:  95.91%; precision:  95.91%; recall:  95.91%; FB1:  95.91%\n",
      "             <e/>: precision:  95.85%; recall:  93.38%; FB1:  94.60%  3206\n",
      "             <f/>: precision:  97.56%; recall:  98.29%; FB1:  97.92%  38225\n",
      "             <i/>: precision:  76.56%; recall:  85.61%; FB1:  80.83%  482\n",
      "            <rm/>: precision:  68.57%; recall:  82.51%; FB1:  74.90%  805\n",
      "           <rms/>: precision:  87.44%; recall:  88.21%; FB1:  87.82%  1489\n",
      "            <rp/>: precision:  68.22%; recall:  44.62%; FB1:  53.95%  365\n",
      "           <rpn/>: precision:  80.03%; recall:  78.53%; FB1:  79.27%  1522\n",
      "        <rpnDel/>: precision:  50.00%; recall:   2.38%; FB1:   4.55%  4\n",
      "           <rps/>: precision:  79.30%; recall:  66.15%; FB1:  72.13%  488\n",
      "                O: precision:  99.95%; recall: 100.00%; FB1:  99.97%  5857\n",
      "\n",
      "Epoch:  10%|███▌                                | 1/10 [05:55<53:15, 355.06s/it]\n",
      "2021-11-09 17:32:23.664795 Step: 1 of 5656 Loss: 0.082709\n",
      "2021-11-09 17:32:29.985381 Step: 100 of 5656 Loss: 0.007664\n",
      "2021-11-09 17:32:35.793936 Step: 200 of 5656 Loss: 0.007396\n",
      "2021-11-09 17:32:42.072221 Step: 300 of 5656 Loss: 0.006773\n",
      "2021-11-09 17:32:48.252162 Step: 400 of 5656 Loss: 0.007938\n",
      "2021-11-09 17:32:54.528660 Step: 500 of 5656 Loss: 0.007689\n",
      "2021-11-09 17:33:00.867737 Step: 600 of 5656 Loss: 0.006793\n",
      "2021-11-09 17:33:07.259493 Step: 700 of 5656 Loss: 0.006214\n",
      "2021-11-09 17:33:13.620913 Step: 800 of 5656 Loss: 0.008104\n",
      "2021-11-09 17:33:20.089774 Step: 900 of 5656 Loss: 0.007778\n",
      "2021-11-09 17:33:26.378129 Step: 1000 of 5656 Loss: 0.007072\n",
      "2021-11-09 17:33:32.795064 Step: 1100 of 5656 Loss: 0.007871\n",
      "2021-11-09 17:33:38.557334 Step: 1200 of 5656 Loss: 0.007266\n",
      "2021-11-09 17:33:44.105400 Step: 1300 of 5656 Loss: 0.008511\n",
      "2021-11-09 17:33:50.131725 Step: 1400 of 5656 Loss: 0.007239\n",
      "2021-11-09 17:33:55.819637 Step: 1500 of 5656 Loss: 0.008035\n",
      "2021-11-09 17:34:01.755766 Step: 1600 of 5656 Loss: 0.008410\n",
      "2021-11-09 17:34:07.713425 Step: 1700 of 5656 Loss: 0.007600\n",
      "2021-11-09 17:34:13.697553 Step: 1800 of 5656 Loss: 0.008344\n",
      "2021-11-09 17:34:19.089118 Step: 1900 of 5656 Loss: 0.007063\n",
      "2021-11-09 17:34:25.312068 Step: 2000 of 5656 Loss: 0.007421\n",
      "2021-11-09 17:34:31.598628 Step: 2100 of 5656 Loss: 0.007805\n",
      "2021-11-09 17:34:37.904135 Step: 2200 of 5656 Loss: 0.007179\n",
      "2021-11-09 17:34:43.818961 Step: 2300 of 5656 Loss: 0.007800\n",
      "2021-11-09 17:34:50.282933 Step: 2400 of 5656 Loss: 0.006916\n",
      "2021-11-09 17:34:56.415778 Step: 2500 of 5656 Loss: 0.006288\n",
      "2021-11-09 17:35:02.450911 Step: 2600 of 5656 Loss: 0.007952\n",
      "2021-11-09 17:35:08.697548 Step: 2700 of 5656 Loss: 0.007693\n",
      "2021-11-09 17:35:15.108637 Step: 2800 of 5656 Loss: 0.006658\n",
      "2021-11-09 17:35:21.354120 Step: 2900 of 5656 Loss: 0.006206\n",
      "2021-11-09 17:35:27.793252 Step: 3000 of 5656 Loss: 0.008596\n",
      "2021-11-09 17:35:34.061375 Step: 3100 of 5656 Loss: 0.007079\n",
      "2021-11-09 17:35:40.349447 Step: 3200 of 5656 Loss: 0.006953\n",
      "2021-11-09 17:35:46.477778 Step: 3300 of 5656 Loss: 0.006617\n",
      "2021-11-09 17:35:52.701444 Step: 3400 of 5656 Loss: 0.007493\n",
      "2021-11-09 17:35:58.988993 Step: 3500 of 5656 Loss: 0.007143\n",
      "2021-11-09 17:36:04.614512 Step: 3600 of 5656 Loss: 0.006978\n",
      "2021-11-09 17:36:10.102959 Step: 3700 of 5656 Loss: 0.006596\n",
      "2021-11-09 17:36:16.604884 Step: 3800 of 5656 Loss: 0.007142\n",
      "2021-11-09 17:36:22.815047 Step: 3900 of 5656 Loss: 0.007367\n",
      "2021-11-09 17:36:29.165631 Step: 4000 of 5656 Loss: 0.008991\n",
      "2021-11-09 17:36:34.760281 Step: 4100 of 5656 Loss: 0.005924\n",
      "2021-11-09 17:36:41.069021 Step: 4200 of 5656 Loss: 0.006793\n",
      "2021-11-09 17:36:47.117497 Step: 4300 of 5656 Loss: 0.008368\n",
      "2021-11-09 17:36:53.200039 Step: 4400 of 5656 Loss: 0.007333\n",
      "2021-11-09 17:36:59.430387 Step: 4500 of 5656 Loss: 0.006164\n",
      "2021-11-09 17:37:05.790941 Step: 4600 of 5656 Loss: 0.008110\n",
      "2021-11-09 17:37:11.891449 Step: 4700 of 5656 Loss: 0.007249\n",
      "2021-11-09 17:37:18.143372 Step: 4800 of 5656 Loss: 0.007999\n",
      "2021-11-09 17:37:24.522184 Step: 4900 of 5656 Loss: 0.005930\n",
      "2021-11-09 17:37:30.750655 Step: 5000 of 5656 Loss: 0.007506\n",
      "2021-11-09 17:37:37.125696 Step: 5100 of 5656 Loss: 0.006662\n",
      "2021-11-09 17:37:43.363178 Step: 5200 of 5656 Loss: 0.006479\n",
      "2021-11-09 17:37:49.698666 Step: 5300 of 5656 Loss: 0.008139\n",
      "2021-11-09 17:37:56.076865 Step: 5400 of 5656 Loss: 0.007091\n",
      "2021-11-09 17:38:02.060129 Step: 5500 of 5656 Loss: 0.008404\n",
      "2021-11-09 17:38:08.356478 Step: 5600 of 5656 Loss: 0.007821\n",
      "Training Loss: 0.073673 for epoch 1\n",
      "Epoch:  1\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50501.\n",
      "accuracy:  95.83%; (non-O)\n",
      "accuracy:  96.30%; precision:  96.30%; recall:  96.30%; FB1:  96.30%\n",
      "             <e/>: precision:  97.07%; recall:  92.46%; FB1:  94.71%  3135\n",
      "             <f/>: precision:  96.86%; recall:  99.22%; FB1:  98.03%  38871\n",
      "             <i/>: precision:  79.91%; recall:  86.77%; FB1:  83.20%  468\n",
      "            <rm/>: precision:  88.95%; recall:  68.61%; FB1:  77.47%  516\n",
      "           <rms/>: precision:  92.96%; recall:  85.84%; FB1:  89.26%  1363\n",
      "            <rp/>: precision:  73.55%; recall:  40.86%; FB1:  52.53%  310\n",
      "           <rpn/>: precision:  86.18%; recall:  78.40%; FB1:  82.11%  1411\n",
      "        <rpnDel/>: precision:  52.63%; recall:  11.90%; FB1:  19.42%  19\n",
      "           <rps/>: precision:  80.85%; recall:  68.55%; FB1:  74.19%  496\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  20%|███████▏                            | 2/10 [11:51<47:24, 355.59s/it]\n",
      "2021-11-09 17:38:19.608911 Step: 1 of 5656 Loss: 0.006539\n",
      "2021-11-09 17:38:25.961992 Step: 100 of 5656 Loss: 0.006303\n",
      "2021-11-09 17:38:32.140256 Step: 200 of 5656 Loss: 0.003532\n",
      "2021-11-09 17:38:38.487546 Step: 300 of 5656 Loss: 0.005554\n",
      "2021-11-09 17:38:44.712370 Step: 400 of 5656 Loss: 0.004548\n",
      "2021-11-09 17:38:50.768882 Step: 500 of 5656 Loss: 0.004659\n",
      "2021-11-09 17:38:57.061301 Step: 600 of 5656 Loss: 0.004814\n",
      "2021-11-09 17:39:03.682441 Step: 700 of 5656 Loss: 0.005088\n",
      "2021-11-09 17:39:09.948011 Step: 800 of 5656 Loss: 0.004543\n",
      "2021-11-09 17:39:16.178968 Step: 900 of 5656 Loss: 0.005657\n",
      "2021-11-09 17:39:22.420360 Step: 1000 of 5656 Loss: 0.006286\n",
      "2021-11-09 17:39:28.489750 Step: 1100 of 5656 Loss: 0.005179\n",
      "2021-11-09 17:39:34.722696 Step: 1200 of 5656 Loss: 0.005349\n",
      "2021-11-09 17:39:40.839256 Step: 1300 of 5656 Loss: 0.005881\n",
      "2021-11-09 17:39:46.632219 Step: 1400 of 5656 Loss: 0.004515\n",
      "2021-11-09 17:39:52.820301 Step: 1500 of 5656 Loss: 0.006689\n",
      "2021-11-09 17:39:59.061009 Step: 1600 of 5656 Loss: 0.004226\n",
      "2021-11-09 17:40:05.409590 Step: 1700 of 5656 Loss: 0.005491\n",
      "2021-11-09 17:40:11.460761 Step: 1800 of 5656 Loss: 0.005127\n",
      "2021-11-09 17:40:16.636776 Step: 1900 of 5656 Loss: 0.004924\n",
      "2021-11-09 17:40:22.131474 Step: 2000 of 5656 Loss: 0.006359\n",
      "2021-11-09 17:40:27.615605 Step: 2100 of 5656 Loss: 0.005493\n",
      "2021-11-09 17:40:33.007580 Step: 2200 of 5656 Loss: 0.006055\n",
      "2021-11-09 17:40:38.337943 Step: 2300 of 5656 Loss: 0.005650\n",
      "2021-11-09 17:40:44.583204 Step: 2400 of 5656 Loss: 0.005297\n",
      "2021-11-09 17:40:50.742669 Step: 2500 of 5656 Loss: 0.005215\n",
      "2021-11-09 17:40:56.926039 Step: 2600 of 5656 Loss: 0.004439\n",
      "2021-11-09 17:41:02.989900 Step: 2700 of 5656 Loss: 0.004794\n",
      "2021-11-09 17:41:09.026342 Step: 2800 of 5656 Loss: 0.005807\n",
      "2021-11-09 17:41:14.766277 Step: 2900 of 5656 Loss: 0.005132\n",
      "2021-11-09 17:41:21.003000 Step: 3000 of 5656 Loss: 0.005581\n",
      "2021-11-09 17:41:26.686288 Step: 3100 of 5656 Loss: 0.006580\n",
      "2021-11-09 17:41:32.848017 Step: 3200 of 5656 Loss: 0.004462\n",
      "2021-11-09 17:41:39.152609 Step: 3300 of 5656 Loss: 0.005241\n",
      "2021-11-09 17:41:44.484659 Step: 3400 of 5656 Loss: 0.005160\n",
      "2021-11-09 17:41:50.266264 Step: 3500 of 5656 Loss: 0.004840\n",
      "2021-11-09 17:41:56.413633 Step: 3600 of 5656 Loss: 0.004032\n",
      "2021-11-09 17:42:02.657927 Step: 3700 of 5656 Loss: 0.005124\n",
      "2021-11-09 17:42:09.109136 Step: 3800 of 5656 Loss: 0.005592\n",
      "2021-11-09 17:42:15.392500 Step: 3900 of 5656 Loss: 0.005446\n",
      "2021-11-09 17:42:21.499210 Step: 4000 of 5656 Loss: 0.004523\n",
      "2021-11-09 17:42:27.586490 Step: 4100 of 5656 Loss: 0.006213\n",
      "2021-11-09 17:42:33.659446 Step: 4200 of 5656 Loss: 0.005030\n",
      "2021-11-09 17:42:39.819691 Step: 4300 of 5656 Loss: 0.005595\n",
      "2021-11-09 17:42:46.208517 Step: 4400 of 5656 Loss: 0.005213\n",
      "2021-11-09 17:42:52.557424 Step: 4500 of 5656 Loss: 0.006305\n",
      "2021-11-09 17:42:58.375178 Step: 4600 of 5656 Loss: 0.005309\n",
      "2021-11-09 17:43:03.699744 Step: 4700 of 5656 Loss: 0.005834\n",
      "2021-11-09 17:43:09.121039 Step: 4800 of 5656 Loss: 0.005139\n",
      "2021-11-09 17:43:15.391152 Step: 4900 of 5656 Loss: 0.005768\n",
      "2021-11-09 17:43:21.479231 Step: 5000 of 5656 Loss: 0.004781\n",
      "2021-11-09 17:43:27.674869 Step: 5100 of 5656 Loss: 0.004287\n",
      "2021-11-09 17:43:33.930247 Step: 5200 of 5656 Loss: 0.006177\n",
      "2021-11-09 17:43:40.300425 Step: 5300 of 5656 Loss: 0.005784\n",
      "2021-11-09 17:43:46.556099 Step: 5400 of 5656 Loss: 0.004602\n",
      "2021-11-09 17:43:52.819669 Step: 5500 of 5656 Loss: 0.004423\n",
      "2021-11-09 17:43:59.097211 Step: 5600 of 5656 Loss: 0.006080\n",
      "Training Loss: 0.052765 for epoch 2\n",
      "Epoch:  2\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50613.\n",
      "accuracy:  96.07%; (non-O)\n",
      "accuracy:  96.51%; precision:  96.51%; recall:  96.51%; FB1:  96.51%\n",
      "             <e/>: precision:  97.05%; recall:  93.89%; FB1:  95.44%  3184\n",
      "             <f/>: precision:  97.60%; recall:  98.78%; FB1:  98.19%  38405\n",
      "             <i/>: precision:  84.79%; recall:  87.94%; FB1:  86.33%  447\n",
      "            <rm/>: precision:  78.72%; recall:  79.07%; FB1:  78.90%  672\n",
      "           <rms/>: precision:  90.25%; recall:  89.02%; FB1:  89.63%  1456\n",
      "            <rp/>: precision:  72.83%; recall:  46.59%; FB1:  56.83%  357\n",
      "           <rpn/>: precision:  84.32%; recall:  81.50%; FB1:  82.89%  1499\n",
      "        <rpnDel/>: precision:  42.59%; recall:  27.38%; FB1:  33.33%  54\n",
      "           <rps/>: precision:  81.17%; recall:  71.45%; FB1:  76.00%  515\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  30%|██████████▊                         | 3/10 [17:48<41:36, 356.57s/it]\n",
      "2021-11-09 17:44:17.374616 Step: 1 of 5656 Loss: 0.043157\n",
      "2021-11-09 17:44:23.478291 Step: 100 of 5656 Loss: 0.004444\n",
      "2021-11-09 17:44:29.682094 Step: 200 of 5656 Loss: 0.003602\n",
      "2021-11-09 17:44:35.934897 Step: 300 of 5656 Loss: 0.003371\n",
      "2021-11-09 17:44:42.159573 Step: 400 of 5656 Loss: 0.003413\n",
      "2021-11-09 17:44:48.390951 Step: 500 of 5656 Loss: 0.003871\n",
      "2021-11-09 17:44:54.607665 Step: 600 of 5656 Loss: 0.004175\n",
      "2021-11-09 17:45:00.887152 Step: 700 of 5656 Loss: 0.003519\n",
      "2021-11-09 17:45:07.132624 Step: 800 of 5656 Loss: 0.003084\n",
      "2021-11-09 17:45:13.285683 Step: 900 of 5656 Loss: 0.005230\n",
      "2021-11-09 17:45:19.474131 Step: 1000 of 5656 Loss: 0.003479\n",
      "2021-11-09 17:45:25.517743 Step: 1100 of 5656 Loss: 0.004127\n",
      "2021-11-09 17:45:31.679034 Step: 1200 of 5656 Loss: 0.003212\n",
      "2021-11-09 17:45:37.902808 Step: 1300 of 5656 Loss: 0.004080\n",
      "2021-11-09 17:45:44.046190 Step: 1400 of 5656 Loss: 0.004047\n",
      "2021-11-09 17:45:50.239718 Step: 1500 of 5656 Loss: 0.003434\n",
      "2021-11-09 17:45:56.572824 Step: 1600 of 5656 Loss: 0.004043\n",
      "2021-11-09 17:46:02.896376 Step: 1700 of 5656 Loss: 0.003757\n",
      "2021-11-09 17:46:09.047560 Step: 1800 of 5656 Loss: 0.004580\n",
      "2021-11-09 17:46:15.343678 Step: 1900 of 5656 Loss: 0.004025\n",
      "2021-11-09 17:46:21.626408 Step: 2000 of 5656 Loss: 0.003732\n",
      "2021-11-09 17:46:27.685035 Step: 2100 of 5656 Loss: 0.004370\n",
      "2021-11-09 17:46:33.861171 Step: 2200 of 5656 Loss: 0.003854\n",
      "2021-11-09 17:46:39.943862 Step: 2300 of 5656 Loss: 0.003871\n",
      "2021-11-09 17:46:46.115032 Step: 2400 of 5656 Loss: 0.003620\n",
      "2021-11-09 17:46:52.221613 Step: 2500 of 5656 Loss: 0.003137\n",
      "2021-11-09 17:46:58.342123 Step: 2600 of 5656 Loss: 0.004340\n",
      "2021-11-09 17:47:04.452471 Step: 2700 of 5656 Loss: 0.003182\n",
      "2021-11-09 17:47:10.619567 Step: 2800 of 5656 Loss: 0.003746\n",
      "2021-11-09 17:47:16.689441 Step: 2900 of 5656 Loss: 0.004252\n",
      "2021-11-09 17:47:22.935158 Step: 3000 of 5656 Loss: 0.004205\n",
      "2021-11-09 17:47:29.348640 Step: 3100 of 5656 Loss: 0.004004\n",
      "2021-11-09 17:47:35.667728 Step: 3200 of 5656 Loss: 0.004681\n",
      "2021-11-09 17:47:41.880200 Step: 3300 of 5656 Loss: 0.003471\n",
      "2021-11-09 17:47:48.054475 Step: 3400 of 5656 Loss: 0.003882\n",
      "2021-11-09 17:47:54.352752 Step: 3500 of 5656 Loss: 0.004316\n",
      "2021-11-09 17:48:00.657283 Step: 3600 of 5656 Loss: 0.003977\n",
      "2021-11-09 17:48:06.931296 Step: 3700 of 5656 Loss: 0.004352\n",
      "2021-11-09 17:48:13.139553 Step: 3800 of 5656 Loss: 0.003364\n",
      "2021-11-09 17:48:19.116275 Step: 3900 of 5656 Loss: 0.004441\n",
      "2021-11-09 17:48:25.373950 Step: 4000 of 5656 Loss: 0.005588\n",
      "2021-11-09 17:48:31.620723 Step: 4100 of 5656 Loss: 0.004205\n",
      "2021-11-09 17:48:37.833551 Step: 4200 of 5656 Loss: 0.003336\n",
      "2021-11-09 17:48:44.036287 Step: 4300 of 5656 Loss: 0.003300\n",
      "2021-11-09 17:48:50.278559 Step: 4400 of 5656 Loss: 0.004501\n",
      "2021-11-09 17:48:56.533507 Step: 4500 of 5656 Loss: 0.004480\n",
      "2021-11-09 17:49:02.849535 Step: 4600 of 5656 Loss: 0.003623\n",
      "2021-11-09 17:49:09.233843 Step: 4700 of 5656 Loss: 0.003662\n",
      "2021-11-09 17:49:15.544616 Step: 4800 of 5656 Loss: 0.003564\n",
      "2021-11-09 17:49:21.346149 Step: 4900 of 5656 Loss: 0.003448\n",
      "2021-11-09 17:49:26.624141 Step: 5000 of 5656 Loss: 0.004113\n",
      "2021-11-09 17:49:31.990479 Step: 5100 of 5656 Loss: 0.003665\n",
      "2021-11-09 17:49:37.389323 Step: 5200 of 5656 Loss: 0.004341\n",
      "2021-11-09 17:49:42.660806 Step: 5300 of 5656 Loss: 0.004573\n",
      "2021-11-09 17:49:48.416907 Step: 5400 of 5656 Loss: 0.003085\n",
      "2021-11-09 17:49:54.599112 Step: 5500 of 5656 Loss: 0.004245\n",
      "2021-11-09 17:50:00.729853 Step: 5600 of 5656 Loss: 0.004597\n",
      "Training Loss: 0.039509 for epoch 3\n",
      "Epoch:  3\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50511.\n",
      "accuracy:  95.85%; (non-O)\n",
      "accuracy:  96.32%; precision:  96.32%; recall:  96.32%; FB1:  96.32%\n",
      "             <e/>: precision:  96.52%; recall:  94.44%; FB1:  95.47%  3220\n",
      "             <f/>: precision:  97.85%; recall:  98.31%; FB1:  98.08%  38124\n",
      "             <i/>: precision:  80.21%; recall:  90.26%; FB1:  84.93%  485\n",
      "            <rm/>: precision:  81.82%; recall:  75.34%; FB1:  78.44%  616\n",
      "           <rms/>: precision:  88.81%; recall:  89.77%; FB1:  89.29%  1492\n",
      "            <rp/>: precision:  70.71%; recall:  48.03%; FB1:  57.20%  379\n",
      "           <rpn/>: precision:  81.37%; recall:  83.37%; FB1:  82.36%  1589\n",
      "        <rpnDel/>: precision:  41.33%; recall:  36.90%; FB1:  38.99%  75\n",
      "           <rps/>: precision:  71.59%; recall:  74.53%; FB1:  73.03%  609\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  40%|██████████████▍                     | 4/10 [23:50<35:50, 358.45s/it]\n",
      "2021-11-09 17:50:18.724987 Step: 1 of 5656 Loss: 0.067326\n",
      "2021-11-09 17:50:24.960326 Step: 100 of 5656 Loss: 0.002473\n",
      "2021-11-09 17:50:31.170628 Step: 200 of 5656 Loss: 0.002453\n",
      "2021-11-09 17:50:37.453956 Step: 300 of 5656 Loss: 0.003364\n",
      "2021-11-09 17:50:43.675409 Step: 400 of 5656 Loss: 0.002942\n",
      "2021-11-09 17:50:49.946782 Step: 500 of 5656 Loss: 0.002741\n",
      "2021-11-09 17:50:56.185270 Step: 600 of 5656 Loss: 0.002568\n",
      "2021-11-09 17:51:02.464739 Step: 700 of 5656 Loss: 0.003027\n",
      "2021-11-09 17:51:08.812633 Step: 800 of 5656 Loss: 0.003086\n",
      "2021-11-09 17:51:14.963257 Step: 900 of 5656 Loss: 0.002561\n",
      "2021-11-09 17:51:20.810604 Step: 1000 of 5656 Loss: 0.002622\n",
      "2021-11-09 17:51:26.808173 Step: 1100 of 5656 Loss: 0.003025\n",
      "2021-11-09 17:51:33.029947 Step: 1200 of 5656 Loss: 0.002332\n",
      "2021-11-09 17:51:39.184837 Step: 1300 of 5656 Loss: 0.002734\n",
      "2021-11-09 17:51:45.163067 Step: 1400 of 5656 Loss: 0.002470\n",
      "2021-11-09 17:51:51.517332 Step: 1500 of 5656 Loss: 0.002718\n",
      "2021-11-09 17:51:57.781552 Step: 1600 of 5656 Loss: 0.003091\n",
      "2021-11-09 17:52:04.028457 Step: 1700 of 5656 Loss: 0.003513\n",
      "2021-11-09 17:52:10.222404 Step: 1800 of 5656 Loss: 0.002381\n",
      "2021-11-09 17:52:16.409441 Step: 1900 of 5656 Loss: 0.002943\n",
      "2021-11-09 17:52:22.648504 Step: 2000 of 5656 Loss: 0.003194\n",
      "2021-11-09 17:52:28.885452 Step: 2100 of 5656 Loss: 0.003354\n",
      "2021-11-09 17:52:35.048894 Step: 2200 of 5656 Loss: 0.003635\n",
      "2021-11-09 17:52:41.159416 Step: 2300 of 5656 Loss: 0.002973\n",
      "2021-11-09 17:52:47.452686 Step: 2400 of 5656 Loss: 0.002442\n",
      "2021-11-09 17:52:53.511943 Step: 2500 of 5656 Loss: 0.002569\n",
      "2021-11-09 17:52:58.820118 Step: 2600 of 5656 Loss: 0.002563\n",
      "2021-11-09 17:53:04.884657 Step: 2700 of 5656 Loss: 0.002699\n",
      "2021-11-09 17:53:11.274655 Step: 2800 of 5656 Loss: 0.002787\n",
      "2021-11-09 17:53:17.504961 Step: 2900 of 5656 Loss: 0.002921\n",
      "2021-11-09 17:53:23.785729 Step: 3000 of 5656 Loss: 0.002959\n",
      "2021-11-09 17:53:30.013824 Step: 3100 of 5656 Loss: 0.002471\n",
      "2021-11-09 17:53:36.157152 Step: 3200 of 5656 Loss: 0.003055\n",
      "2021-11-09 17:53:42.328527 Step: 3300 of 5656 Loss: 0.002872\n",
      "2021-11-09 17:53:48.314242 Step: 3400 of 5656 Loss: 0.003093\n",
      "2021-11-09 17:53:54.283681 Step: 3500 of 5656 Loss: 0.002989\n",
      "2021-11-09 17:54:00.655183 Step: 3600 of 5656 Loss: 0.003516\n",
      "2021-11-09 17:54:06.977539 Step: 3700 of 5656 Loss: 0.002490\n",
      "2021-11-09 17:54:13.198646 Step: 3800 of 5656 Loss: 0.002804\n",
      "2021-11-09 17:54:19.183073 Step: 3900 of 5656 Loss: 0.003712\n",
      "2021-11-09 17:54:25.472520 Step: 4000 of 5656 Loss: 0.003256\n",
      "2021-11-09 17:54:31.687303 Step: 4100 of 5656 Loss: 0.002384\n",
      "2021-11-09 17:54:38.019865 Step: 4200 of 5656 Loss: 0.003185\n",
      "2021-11-09 17:54:44.441132 Step: 4300 of 5656 Loss: 0.003250\n",
      "2021-11-09 17:54:50.809525 Step: 4400 of 5656 Loss: 0.003181\n",
      "2021-11-09 17:54:56.556790 Step: 4500 of 5656 Loss: 0.003117\n",
      "2021-11-09 17:55:02.261692 Step: 4600 of 5656 Loss: 0.003549\n",
      "2021-11-09 17:55:08.488647 Step: 4700 of 5656 Loss: 0.002455\n",
      "2021-11-09 17:55:14.742384 Step: 4800 of 5656 Loss: 0.003007\n",
      "2021-11-09 17:55:20.996889 Step: 4900 of 5656 Loss: 0.003829\n",
      "2021-11-09 17:55:26.409305 Step: 5000 of 5656 Loss: 0.002437\n",
      "2021-11-09 17:55:31.864961 Step: 5100 of 5656 Loss: 0.002773\n",
      "2021-11-09 17:55:37.079137 Step: 5200 of 5656 Loss: 0.002845\n",
      "2021-11-09 17:55:42.802697 Step: 5300 of 5656 Loss: 0.003332\n",
      "2021-11-09 17:55:49.170351 Step: 5400 of 5656 Loss: 0.002999\n",
      "2021-11-09 17:55:55.371624 Step: 5500 of 5656 Loss: 0.003116\n",
      "2021-11-09 17:56:01.424846 Step: 5600 of 5656 Loss: 0.003560\n",
      "Training Loss: 0.029392 for epoch 4\n",
      "Epoch:  4\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50578.\n",
      "accuracy:  96.00%; (non-O)\n",
      "accuracy:  96.44%; precision:  96.44%; recall:  96.44%; FB1:  96.44%\n",
      "             <e/>: precision:  96.19%; recall:  94.47%; FB1:  95.32%  3232\n",
      "             <f/>: precision:  97.66%; recall:  98.67%; FB1:  98.16%  38336\n",
      "             <i/>: precision:  83.93%; recall:  87.24%; FB1:  85.55%  448\n",
      "            <rm/>: precision:  86.04%; recall:  73.69%; FB1:  79.39%  573\n",
      "           <rms/>: precision:  90.23%; recall:  90.11%; FB1:  90.17%  1474\n",
      "            <rp/>: precision:  71.92%; recall:  44.98%; FB1:  55.35%  349\n",
      "           <rpn/>: precision:  82.28%; recall:  81.43%; FB1:  81.85%  1535\n",
      "        <rpnDel/>: precision:  49.25%; recall:  39.29%; FB1:  43.71%  67\n",
      "           <rps/>: precision:  74.96%; recall:  73.68%; FB1:  74.31%  575\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  50%|██████████████████                  | 5/10 [29:50<29:56, 359.25s/it]\n",
      "2021-11-09 17:56:19.350388 Step: 1 of 5656 Loss: 0.007892\n",
      "2021-11-09 17:56:25.493380 Step: 100 of 5656 Loss: 0.001934\n",
      "2021-11-09 17:56:31.840918 Step: 200 of 5656 Loss: 0.001919\n",
      "2021-11-09 17:56:38.104523 Step: 300 of 5656 Loss: 0.002336\n",
      "2021-11-09 17:56:44.355552 Step: 400 of 5656 Loss: 0.001983\n",
      "2021-11-09 17:56:50.602095 Step: 500 of 5656 Loss: 0.001970\n",
      "2021-11-09 17:56:56.772528 Step: 600 of 5656 Loss: 0.002610\n",
      "2021-11-09 17:57:02.535037 Step: 700 of 5656 Loss: 0.002245\n",
      "2021-11-09 17:57:08.734920 Step: 800 of 5656 Loss: 0.002397\n",
      "2021-11-09 17:57:15.128487 Step: 900 of 5656 Loss: 0.001927\n",
      "2021-11-09 17:57:21.343609 Step: 1000 of 5656 Loss: 0.002150\n",
      "2021-11-09 17:57:27.689931 Step: 1100 of 5656 Loss: 0.001926\n",
      "2021-11-09 17:57:33.810982 Step: 1200 of 5656 Loss: 0.001583\n",
      "2021-11-09 17:57:40.042703 Step: 1300 of 5656 Loss: 0.002447\n",
      "2021-11-09 17:57:46.281270 Step: 1400 of 5656 Loss: 0.001962\n",
      "2021-11-09 17:57:52.417377 Step: 1500 of 5656 Loss: 0.002381\n",
      "2021-11-09 17:57:58.611400 Step: 1600 of 5656 Loss: 0.002018\n",
      "2021-11-09 17:58:04.869010 Step: 1700 of 5656 Loss: 0.002146\n",
      "2021-11-09 17:58:10.878266 Step: 1800 of 5656 Loss: 0.002656\n",
      "2021-11-09 17:58:17.185932 Step: 1900 of 5656 Loss: 0.002021\n",
      "2021-11-09 17:58:23.419722 Step: 2000 of 5656 Loss: 0.002289\n",
      "2021-11-09 17:58:29.658194 Step: 2100 of 5656 Loss: 0.002622\n",
      "2021-11-09 17:58:35.891250 Step: 2200 of 5656 Loss: 0.002273\n",
      "2021-11-09 17:58:42.126651 Step: 2300 of 5656 Loss: 0.002381\n",
      "2021-11-09 17:58:48.586050 Step: 2400 of 5656 Loss: 0.002068\n",
      "2021-11-09 17:58:53.977933 Step: 2500 of 5656 Loss: 0.002605\n",
      "2021-11-09 17:58:59.798486 Step: 2600 of 5656 Loss: 0.002298\n",
      "2021-11-09 17:59:05.982920 Step: 2700 of 5656 Loss: 0.002262\n",
      "2021-11-09 17:59:12.214383 Step: 2800 of 5656 Loss: 0.002029\n",
      "2021-11-09 17:59:18.467361 Step: 2900 of 5656 Loss: 0.002221\n",
      "2021-11-09 17:59:24.075879 Step: 3000 of 5656 Loss: 0.001750\n",
      "2021-11-09 17:59:30.229458 Step: 3100 of 5656 Loss: 0.002590\n",
      "2021-11-09 17:59:36.495686 Step: 3200 of 5656 Loss: 0.002463\n",
      "2021-11-09 17:59:42.450868 Step: 3300 of 5656 Loss: 0.002160\n",
      "2021-11-09 17:59:48.386981 Step: 3400 of 5656 Loss: 0.002139\n",
      "2021-11-09 17:59:54.552234 Step: 3500 of 5656 Loss: 0.001480\n",
      "2021-11-09 18:00:00.825318 Step: 3600 of 5656 Loss: 0.002578\n",
      "2021-11-09 18:00:06.882869 Step: 3700 of 5656 Loss: 0.001689\n",
      "2021-11-09 18:00:13.082425 Step: 3800 of 5656 Loss: 0.001693\n",
      "2021-11-09 18:00:19.226568 Step: 3900 of 5656 Loss: 0.001602\n",
      "2021-11-09 18:00:25.551646 Step: 4000 of 5656 Loss: 0.001918\n",
      "2021-11-09 18:00:31.878808 Step: 4100 of 5656 Loss: 0.002684\n",
      "2021-11-09 18:00:37.840788 Step: 4200 of 5656 Loss: 0.002095\n",
      "2021-11-09 18:00:43.995368 Step: 4300 of 5656 Loss: 0.001983\n",
      "2021-11-09 18:00:50.165863 Step: 4400 of 5656 Loss: 0.001942\n",
      "2021-11-09 18:00:56.400665 Step: 4500 of 5656 Loss: 0.001789\n",
      "2021-11-09 18:01:02.573911 Step: 4600 of 5656 Loss: 0.002265\n",
      "2021-11-09 18:01:08.615799 Step: 4700 of 5656 Loss: 0.002201\n",
      "2021-11-09 18:01:14.774253 Step: 4800 of 5656 Loss: 0.002182\n",
      "2021-11-09 18:01:20.782013 Step: 4900 of 5656 Loss: 0.002121\n",
      "2021-11-09 18:01:26.835621 Step: 5000 of 5656 Loss: 0.002354\n",
      "2021-11-09 18:01:32.223895 Step: 5100 of 5656 Loss: 0.001753\n",
      "2021-11-09 18:01:37.531506 Step: 5200 of 5656 Loss: 0.002414\n",
      "2021-11-09 18:01:42.850654 Step: 5300 of 5656 Loss: 0.001719\n",
      "2021-11-09 18:01:48.288182 Step: 5400 of 5656 Loss: 0.002393\n",
      "2021-11-09 18:01:53.530461 Step: 5500 of 5656 Loss: 0.002098\n",
      "2021-11-09 18:01:59.563379 Step: 5600 of 5656 Loss: 0.002424\n",
      "Training Loss: 0.021434 for epoch 5\n",
      "Epoch:  5\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50721.\n",
      "accuracy:  96.30%; (non-O)\n",
      "accuracy:  96.72%; precision:  96.72%; recall:  96.72%; FB1:  96.72%\n",
      "             <e/>: precision:  96.22%; recall:  95.17%; FB1:  95.69%  3255\n",
      "             <f/>: precision:  97.45%; recall:  99.16%; FB1:  98.30%  38611\n",
      "             <i/>: precision:  89.78%; recall:  83.53%; FB1:  86.54%  401\n",
      "            <rm/>: precision:  86.21%; recall:  73.84%; FB1:  79.55%  573\n",
      "           <rms/>: precision:  92.39%; recall:  89.63%; FB1:  90.99%  1432\n",
      "            <rp/>: precision:  78.95%; recall:  43.01%; FB1:  55.68%  304\n",
      "           <rpn/>: precision:  86.43%; recall:  80.46%; FB1:  83.34%  1444\n",
      "        <rpnDel/>: precision:  51.25%; recall:  48.81%; FB1:  50.00%  80\n",
      "           <rps/>: precision:  82.62%; recall:  69.06%; FB1:  75.23%  489\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  60%|█████████████████████▌              | 6/10 [35:42<23:46, 356.60s/it]\n",
      "2021-11-09 18:02:10.783599 Step: 1 of 5656 Loss: 0.002095\n",
      "2021-11-09 18:02:16.766007 Step: 100 of 5656 Loss: 0.000981\n",
      "2021-11-09 18:02:23.016199 Step: 200 of 5656 Loss: 0.001687\n",
      "2021-11-09 18:02:29.169202 Step: 300 of 5656 Loss: 0.001515\n",
      "2021-11-09 18:02:35.300954 Step: 400 of 5656 Loss: 0.001299\n",
      "2021-11-09 18:02:41.520997 Step: 500 of 5656 Loss: 0.001511\n",
      "2021-11-09 18:02:47.810217 Step: 600 of 5656 Loss: 0.001277\n",
      "2021-11-09 18:02:53.844041 Step: 700 of 5656 Loss: 0.001908\n",
      "2021-11-09 18:02:59.357562 Step: 800 of 5656 Loss: 0.001682\n",
      "2021-11-09 18:03:05.503621 Step: 900 of 5656 Loss: 0.001846\n",
      "2021-11-09 18:03:11.713413 Step: 1000 of 5656 Loss: 0.001450\n",
      "2021-11-09 18:03:17.970313 Step: 1100 of 5656 Loss: 0.001241\n",
      "2021-11-09 18:03:24.219010 Step: 1200 of 5656 Loss: 0.001607\n",
      "2021-11-09 18:03:30.504254 Step: 1300 of 5656 Loss: 0.001823\n",
      "2021-11-09 18:03:36.311037 Step: 1400 of 5656 Loss: 0.001491\n",
      "2021-11-09 18:03:41.765086 Step: 1500 of 5656 Loss: 0.001709\n",
      "2021-11-09 18:03:47.083823 Step: 1600 of 5656 Loss: 0.001586\n",
      "2021-11-09 18:03:52.312499 Step: 1700 of 5656 Loss: 0.001230\n",
      "2021-11-09 18:03:57.819086 Step: 1800 of 5656 Loss: 0.001551\n",
      "2021-11-09 18:04:03.125503 Step: 1900 of 5656 Loss: 0.001500\n",
      "2021-11-09 18:04:09.259268 Step: 2000 of 5656 Loss: 0.001696\n",
      "2021-11-09 18:04:15.386438 Step: 2100 of 5656 Loss: 0.001608\n",
      "2021-11-09 18:04:21.590282 Step: 2200 of 5656 Loss: 0.001667\n",
      "2021-11-09 18:04:27.746822 Step: 2300 of 5656 Loss: 0.001695\n",
      "2021-11-09 18:04:33.965165 Step: 2400 of 5656 Loss: 0.001469\n",
      "2021-11-09 18:04:39.521866 Step: 2500 of 5656 Loss: 0.001488\n",
      "2021-11-09 18:04:45.692266 Step: 2600 of 5656 Loss: 0.001830\n",
      "2021-11-09 18:04:51.873144 Step: 2700 of 5656 Loss: 0.001668\n",
      "2021-11-09 18:04:58.184675 Step: 2800 of 5656 Loss: 0.001474\n",
      "2021-11-09 18:05:04.496210 Step: 2900 of 5656 Loss: 0.001336\n",
      "2021-11-09 18:05:10.537463 Step: 3000 of 5656 Loss: 0.001563\n",
      "2021-11-09 18:05:16.651026 Step: 3100 of 5656 Loss: 0.001172\n",
      "2021-11-09 18:05:23.057551 Step: 3200 of 5656 Loss: 0.001658\n",
      "2021-11-09 18:05:28.445421 Step: 3300 of 5656 Loss: 0.001324\n",
      "2021-11-09 18:05:33.574610 Step: 3400 of 5656 Loss: 0.001426\n",
      "2021-11-09 18:05:38.783754 Step: 3500 of 5656 Loss: 0.001504\n",
      "2021-11-09 18:05:44.308717 Step: 3600 of 5656 Loss: 0.001409\n",
      "2021-11-09 18:05:50.053694 Step: 3700 of 5656 Loss: 0.001441\n",
      "2021-11-09 18:05:56.456669 Step: 3800 of 5656 Loss: 0.001763\n",
      "2021-11-09 18:06:02.792960 Step: 3900 of 5656 Loss: 0.001759\n",
      "2021-11-09 18:06:09.154472 Step: 4000 of 5656 Loss: 0.001080\n",
      "2021-11-09 18:06:15.393205 Step: 4100 of 5656 Loss: 0.001511\n",
      "2021-11-09 18:06:21.719701 Step: 4200 of 5656 Loss: 0.001501\n",
      "2021-11-09 18:06:27.881560 Step: 4300 of 5656 Loss: 0.001263\n",
      "2021-11-09 18:06:33.183202 Step: 4400 of 5656 Loss: 0.001672\n",
      "2021-11-09 18:06:38.633062 Step: 4500 of 5656 Loss: 0.001079\n",
      "2021-11-09 18:06:44.877918 Step: 4600 of 5656 Loss: 0.001768\n",
      "2021-11-09 18:06:51.069579 Step: 4700 of 5656 Loss: 0.001587\n",
      "2021-11-09 18:06:57.430024 Step: 4800 of 5656 Loss: 0.001480\n",
      "2021-11-09 18:07:03.702526 Step: 4900 of 5656 Loss: 0.001143\n",
      "2021-11-09 18:07:10.059036 Step: 5000 of 5656 Loss: 0.001484\n",
      "2021-11-09 18:07:16.197639 Step: 5100 of 5656 Loss: 0.001953\n",
      "2021-11-09 18:07:22.398859 Step: 5200 of 5656 Loss: 0.001295\n",
      "2021-11-09 18:07:28.553304 Step: 5300 of 5656 Loss: 0.001920\n",
      "2021-11-09 18:07:34.544587 Step: 5400 of 5656 Loss: 0.001927\n",
      "2021-11-09 18:07:40.343099 Step: 5500 of 5656 Loss: 0.001889\n",
      "2021-11-09 18:07:46.537185 Step: 5600 of 5656 Loss: 0.001183\n",
      "Training Loss: 0.015325 for epoch 6\n",
      "Epoch:  6\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50693.\n",
      "accuracy:  96.24%; (non-O)\n",
      "accuracy:  96.66%; precision:  96.66%; recall:  96.66%; FB1:  96.66%\n",
      "             <e/>: precision:  95.79%; recall:  95.44%; FB1:  95.62%  3279\n",
      "             <f/>: precision:  97.82%; recall:  98.71%; FB1:  98.26%  38288\n",
      "             <i/>: precision:  88.31%; recall:  85.85%; FB1:  87.06%  419\n",
      "            <rm/>: precision:  82.10%; recall:  76.08%; FB1:  78.98%  620\n",
      "           <rms/>: precision:  91.46%; recall:  90.72%; FB1:  91.09%  1464\n",
      "            <rp/>: precision:  70.92%; recall:  49.82%; FB1:  58.53%  392\n",
      "           <rpn/>: precision:  85.10%; recall:  81.75%; FB1:  83.39%  1490\n",
      "        <rpnDel/>: precision:  54.22%; recall:  53.57%; FB1:  53.89%  83\n",
      "           <rps/>: precision:  78.52%; recall:  74.36%; FB1:  76.38%  554\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  70%|█████████████████████████▏          | 7/10 [41:29<17:40, 353.43s/it]\n",
      "2021-11-09 18:07:57.676772 Step: 1 of 5656 Loss: 0.010274\n",
      "2021-11-09 18:08:03.952956 Step: 100 of 5656 Loss: 0.001045\n",
      "2021-11-09 18:08:10.220356 Step: 200 of 5656 Loss: 0.000984\n",
      "2021-11-09 18:08:16.344923 Step: 300 of 5656 Loss: 0.000977\n",
      "2021-11-09 18:08:21.884535 Step: 400 of 5656 Loss: 0.000925\n",
      "2021-11-09 18:08:27.584257 Step: 500 of 5656 Loss: 0.001138\n",
      "2021-11-09 18:08:33.740266 Step: 600 of 5656 Loss: 0.000837\n",
      "2021-11-09 18:08:39.896883 Step: 700 of 5656 Loss: 0.001008\n",
      "2021-11-09 18:08:45.737629 Step: 800 of 5656 Loss: 0.001197\n",
      "2021-11-09 18:08:51.233056 Step: 900 of 5656 Loss: 0.000875\n",
      "2021-11-09 18:08:57.276709 Step: 1000 of 5656 Loss: 0.001016\n",
      "2021-11-09 18:09:03.476133 Step: 1100 of 5656 Loss: 0.000894\n",
      "2021-11-09 18:09:09.786552 Step: 1200 of 5656 Loss: 0.001089\n",
      "2021-11-09 18:09:16.152556 Step: 1300 of 5656 Loss: 0.000876\n",
      "2021-11-09 18:09:21.983870 Step: 1400 of 5656 Loss: 0.000762\n",
      "2021-11-09 18:09:27.405787 Step: 1500 of 5656 Loss: 0.001106\n",
      "2021-11-09 18:09:33.606640 Step: 1600 of 5656 Loss: 0.000817\n",
      "2021-11-09 18:09:39.685754 Step: 1700 of 5656 Loss: 0.000904\n",
      "2021-11-09 18:09:45.930749 Step: 1800 of 5656 Loss: 0.001134\n",
      "2021-11-09 18:09:52.168084 Step: 1900 of 5656 Loss: 0.000945\n",
      "2021-11-09 18:09:58.299427 Step: 2000 of 5656 Loss: 0.001015\n",
      "2021-11-09 18:10:04.662202 Step: 2100 of 5656 Loss: 0.000991\n",
      "2021-11-09 18:10:10.899789 Step: 2200 of 5656 Loss: 0.000898\n",
      "2021-11-09 18:10:17.170591 Step: 2300 of 5656 Loss: 0.001124\n",
      "2021-11-09 18:10:23.465478 Step: 2400 of 5656 Loss: 0.001122\n",
      "2021-11-09 18:10:29.826092 Step: 2500 of 5656 Loss: 0.001074\n",
      "2021-11-09 18:10:36.193392 Step: 2600 of 5656 Loss: 0.001063\n",
      "2021-11-09 18:10:42.368445 Step: 2700 of 5656 Loss: 0.001150\n",
      "2021-11-09 18:10:48.219089 Step: 2800 of 5656 Loss: 0.001173\n",
      "2021-11-09 18:10:54.348011 Step: 2900 of 5656 Loss: 0.000942\n",
      "2021-11-09 18:11:00.698962 Step: 3000 of 5656 Loss: 0.001146\n",
      "2021-11-09 18:11:06.978451 Step: 3100 of 5656 Loss: 0.001419\n",
      "2021-11-09 18:11:13.354362 Step: 3200 of 5656 Loss: 0.001212\n",
      "2021-11-09 18:11:19.624731 Step: 3300 of 5656 Loss: 0.000898\n",
      "2021-11-09 18:11:25.816904 Step: 3400 of 5656 Loss: 0.001380\n",
      "2021-11-09 18:11:31.938455 Step: 3500 of 5656 Loss: 0.001008\n",
      "2021-11-09 18:11:38.371717 Step: 3600 of 5656 Loss: 0.000644\n",
      "2021-11-09 18:11:44.539984 Step: 3700 of 5656 Loss: 0.001174\n",
      "2021-11-09 18:11:50.888028 Step: 3800 of 5656 Loss: 0.001361\n",
      "2021-11-09 18:11:56.608126 Step: 3900 of 5656 Loss: 0.001021\n",
      "2021-11-09 18:12:02.171991 Step: 4000 of 5656 Loss: 0.001134\n",
      "2021-11-09 18:12:07.532372 Step: 4100 of 5656 Loss: 0.000897\n",
      "2021-11-09 18:12:13.482666 Step: 4200 of 5656 Loss: 0.001039\n",
      "2021-11-09 18:12:19.654503 Step: 4300 of 5656 Loss: 0.001003\n",
      "2021-11-09 18:12:25.864478 Step: 4400 of 5656 Loss: 0.000823\n",
      "2021-11-09 18:12:32.009873 Step: 4500 of 5656 Loss: 0.001113\n",
      "2021-11-09 18:12:38.202588 Step: 4600 of 5656 Loss: 0.001010\n",
      "2021-11-09 18:12:44.515229 Step: 4700 of 5656 Loss: 0.001347\n",
      "2021-11-09 18:12:50.859369 Step: 4800 of 5656 Loss: 0.001122\n",
      "2021-11-09 18:12:56.986208 Step: 4900 of 5656 Loss: 0.000988\n",
      "2021-11-09 18:13:03.203491 Step: 5000 of 5656 Loss: 0.000621\n",
      "2021-11-09 18:13:09.492429 Step: 5100 of 5656 Loss: 0.000638\n",
      "2021-11-09 18:13:15.656722 Step: 5200 of 5656 Loss: 0.001208\n",
      "2021-11-09 18:13:21.597944 Step: 5300 of 5656 Loss: 0.000723\n",
      "2021-11-09 18:13:27.886831 Step: 5400 of 5656 Loss: 0.001059\n",
      "2021-11-09 18:13:34.164886 Step: 5500 of 5656 Loss: 0.000960\n",
      "2021-11-09 18:13:39.964296 Step: 5600 of 5656 Loss: 0.000985\n",
      "Training Loss: 0.010181 for epoch 7\n",
      "Epoch:  7\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50739.\n",
      "accuracy:  96.34%; (non-O)\n",
      "accuracy:  96.75%; precision:  96.75%; recall:  96.75%; FB1:  96.75%\n",
      "             <e/>: precision:  96.65%; recall:  94.68%; FB1:  95.66%  3224\n",
      "             <f/>: precision:  97.59%; recall:  98.95%; FB1:  98.26%  38470\n",
      "             <i/>: precision:  87.16%; recall:  88.17%; FB1:  87.66%  436\n",
      "            <rm/>: precision:  87.13%; recall:  74.89%; FB1:  80.55%  575\n",
      "           <rms/>: precision:  92.26%; recall:  90.45%; FB1:  91.34%  1447\n",
      "            <rp/>: precision:  79.49%; recall:  44.44%; FB1:  57.01%  312\n",
      "           <rpn/>: precision:  84.49%; recall:  83.24%; FB1:  83.86%  1528\n",
      "        <rpnDel/>: precision:  59.26%; recall:  57.14%; FB1:  58.18%  81\n",
      "           <rps/>: precision:  81.78%; recall:  72.14%; FB1:  76.66%  516\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  80%|████████████████████████████▊       | 8/10 [47:22<11:46, 353.29s/it]\n",
      "2021-11-09 18:13:50.661826 Step: 1 of 5656 Loss: 0.059310\n",
      "2021-11-09 18:13:56.605395 Step: 100 of 5656 Loss: 0.000887\n",
      "2021-11-09 18:14:02.355127 Step: 200 of 5656 Loss: 0.000692\n",
      "2021-11-09 18:14:08.449786 Step: 300 of 5656 Loss: 0.000631\n",
      "2021-11-09 18:14:14.619453 Step: 400 of 5656 Loss: 0.000706\n",
      "2021-11-09 18:14:20.680352 Step: 500 of 5656 Loss: 0.000974\n",
      "2021-11-09 18:14:26.062573 Step: 600 of 5656 Loss: 0.000711\n",
      "2021-11-09 18:14:31.343288 Step: 700 of 5656 Loss: 0.000754\n",
      "2021-11-09 18:14:37.214133 Step: 800 of 5656 Loss: 0.000692\n",
      "2021-11-09 18:14:43.425587 Step: 900 of 5656 Loss: 0.000634\n",
      "2021-11-09 18:14:49.719724 Step: 1000 of 5656 Loss: 0.000646\n",
      "2021-11-09 18:14:55.876171 Step: 1100 of 5656 Loss: 0.000603\n",
      "2021-11-09 18:15:02.167205 Step: 1200 of 5656 Loss: 0.000887\n",
      "2021-11-09 18:15:08.331128 Step: 1300 of 5656 Loss: 0.000488\n",
      "2021-11-09 18:15:14.393394 Step: 1400 of 5656 Loss: 0.000772\n",
      "2021-11-09 18:15:20.730860 Step: 1500 of 5656 Loss: 0.000694\n",
      "2021-11-09 18:15:26.942256 Step: 1600 of 5656 Loss: 0.000701\n",
      "2021-11-09 18:15:33.216113 Step: 1700 of 5656 Loss: 0.000781\n",
      "2021-11-09 18:15:39.213078 Step: 1800 of 5656 Loss: 0.000823\n",
      "2021-11-09 18:15:45.315536 Step: 1900 of 5656 Loss: 0.000767\n",
      "2021-11-09 18:15:50.940247 Step: 2000 of 5656 Loss: 0.000684\n",
      "2021-11-09 18:15:56.337723 Step: 2100 of 5656 Loss: 0.000616\n",
      "2021-11-09 18:16:02.315253 Step: 2200 of 5656 Loss: 0.000666\n",
      "2021-11-09 18:16:08.512047 Step: 2300 of 5656 Loss: 0.000883\n",
      "2021-11-09 18:16:14.891353 Step: 2400 of 5656 Loss: 0.001096\n",
      "2021-11-09 18:16:21.099849 Step: 2500 of 5656 Loss: 0.000653\n",
      "2021-11-09 18:16:27.178571 Step: 2600 of 5656 Loss: 0.000707\n",
      "2021-11-09 18:16:33.292206 Step: 2700 of 5656 Loss: 0.000727\n",
      "2021-11-09 18:16:39.451193 Step: 2800 of 5656 Loss: 0.000791\n",
      "2021-11-09 18:16:45.611746 Step: 2900 of 5656 Loss: 0.000692\n",
      "2021-11-09 18:16:51.973368 Step: 3000 of 5656 Loss: 0.000782\n",
      "2021-11-09 18:16:58.133277 Step: 3100 of 5656 Loss: 0.000793\n",
      "2021-11-09 18:17:04.398798 Step: 3200 of 5656 Loss: 0.000594\n",
      "2021-11-09 18:17:10.855482 Step: 3300 of 5656 Loss: 0.000712\n",
      "2021-11-09 18:17:17.102461 Step: 3400 of 5656 Loss: 0.000681\n",
      "2021-11-09 18:17:23.335657 Step: 3500 of 5656 Loss: 0.000521\n",
      "2021-11-09 18:17:29.487677 Step: 3600 of 5656 Loss: 0.000473\n",
      "2021-11-09 18:17:35.561785 Step: 3700 of 5656 Loss: 0.000780\n",
      "2021-11-09 18:17:41.078509 Step: 3800 of 5656 Loss: 0.000916\n",
      "2021-11-09 18:17:46.949469 Step: 3900 of 5656 Loss: 0.000698\n",
      "2021-11-09 18:17:52.568323 Step: 4000 of 5656 Loss: 0.000525\n",
      "2021-11-09 18:17:58.714099 Step: 4100 of 5656 Loss: 0.000709\n",
      "2021-11-09 18:18:04.983168 Step: 4200 of 5656 Loss: 0.000688\n",
      "2021-11-09 18:18:11.024203 Step: 4300 of 5656 Loss: 0.000759\n",
      "2021-11-09 18:18:16.676288 Step: 4400 of 5656 Loss: 0.000528\n",
      "2021-11-09 18:18:22.014365 Step: 4500 of 5656 Loss: 0.000816\n",
      "2021-11-09 18:18:27.225244 Step: 4600 of 5656 Loss: 0.000596\n",
      "2021-11-09 18:18:33.015965 Step: 4700 of 5656 Loss: 0.000713\n",
      "2021-11-09 18:18:39.183215 Step: 4800 of 5656 Loss: 0.000532\n",
      "2021-11-09 18:18:45.385220 Step: 4900 of 5656 Loss: 0.000580\n",
      "2021-11-09 18:18:51.808903 Step: 5000 of 5656 Loss: 0.000861\n",
      "2021-11-09 18:18:58.184865 Step: 5100 of 5656 Loss: 0.000589\n",
      "2021-11-09 18:19:04.616690 Step: 5200 of 5656 Loss: 0.000735\n",
      "2021-11-09 18:19:10.608957 Step: 5300 of 5656 Loss: 0.000695\n",
      "2021-11-09 18:19:16.835389 Step: 5400 of 5656 Loss: 0.000735\n",
      "2021-11-09 18:19:22.750451 Step: 5500 of 5656 Loss: 0.000625\n",
      "2021-11-09 18:19:28.998988 Step: 5600 of 5656 Loss: 0.000762\n",
      "Training Loss: 0.007086 for epoch 8\n",
      "Epoch:  8\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50702.\n",
      "accuracy:  96.26%; (non-O)\n",
      "accuracy:  96.68%; precision:  96.68%; recall:  96.68%; FB1:  96.68%\n",
      "             <e/>: precision:  96.47%; recall:  94.68%; FB1:  95.57%  3230\n",
      "             <f/>: precision:  97.68%; recall:  98.76%; FB1:  98.22%  38362\n",
      "             <i/>: precision:  87.53%; recall:  86.31%; FB1:  86.92%  425\n",
      "            <rm/>: precision:  85.04%; recall:  75.64%; FB1:  80.06%  595\n",
      "           <rms/>: precision:  91.09%; recall:  90.79%; FB1:  90.94%  1471\n",
      "            <rp/>: precision:  75.28%; recall:  48.03%; FB1:  58.64%  356\n",
      "           <rpn/>: precision:  84.86%; recall:  83.49%; FB1:  84.17%  1526\n",
      "        <rpnDel/>: precision:  56.10%; recall:  54.76%; FB1:  55.42%  82\n",
      "           <rps/>: precision:  79.89%; recall:  74.02%; FB1:  76.84%  542\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch:  90%|████████████████████████████████▍   | 9/10 [53:11<05:52, 352.13s/it]\n",
      "2021-11-09 18:19:40.249715 Step: 1 of 5656 Loss: 0.001810\n",
      "2021-11-09 18:19:46.631550 Step: 100 of 5656 Loss: 0.000461\n",
      "2021-11-09 18:19:52.925481 Step: 200 of 5656 Loss: 0.000432\n",
      "2021-11-09 18:19:59.241664 Step: 300 of 5656 Loss: 0.000486\n",
      "2021-11-09 18:20:05.509417 Step: 400 of 5656 Loss: 0.000386\n",
      "2021-11-09 18:20:11.810800 Step: 500 of 5656 Loss: 0.000313\n",
      "2021-11-09 18:20:17.986498 Step: 600 of 5656 Loss: 0.000541\n",
      "2021-11-09 18:20:24.211137 Step: 700 of 5656 Loss: 0.000528\n",
      "2021-11-09 18:20:30.120445 Step: 800 of 5656 Loss: 0.000476\n",
      "2021-11-09 18:20:36.562539 Step: 900 of 5656 Loss: 0.000606\n",
      "2021-11-09 18:20:42.808496 Step: 1000 of 5656 Loss: 0.000459\n",
      "2021-11-09 18:20:48.577575 Step: 1100 of 5656 Loss: 0.000773\n",
      "2021-11-09 18:20:54.765865 Step: 1200 of 5656 Loss: 0.000512\n",
      "2021-11-09 18:21:01.099224 Step: 1300 of 5656 Loss: 0.000639\n",
      "2021-11-09 18:21:07.222347 Step: 1400 of 5656 Loss: 0.000292\n",
      "2021-11-09 18:21:12.864572 Step: 1500 of 5656 Loss: 0.000742\n",
      "2021-11-09 18:21:19.223956 Step: 1600 of 5656 Loss: 0.000475\n",
      "2021-11-09 18:21:25.620040 Step: 1700 of 5656 Loss: 0.000512\n",
      "2021-11-09 18:21:31.521921 Step: 1800 of 5656 Loss: 0.000488\n",
      "2021-11-09 18:21:37.291187 Step: 1900 of 5656 Loss: 0.000444\n",
      "2021-11-09 18:21:43.521217 Step: 2000 of 5656 Loss: 0.000329\n",
      "2021-11-09 18:21:49.594623 Step: 2100 of 5656 Loss: 0.000527\n",
      "2021-11-09 18:21:55.936524 Step: 2200 of 5656 Loss: 0.000404\n",
      "2021-11-09 18:22:02.240764 Step: 2300 of 5656 Loss: 0.000598\n",
      "2021-11-09 18:22:08.345340 Step: 2400 of 5656 Loss: 0.000617\n",
      "2021-11-09 18:22:13.773948 Step: 2500 of 5656 Loss: 0.000387\n",
      "2021-11-09 18:22:19.995889 Step: 2600 of 5656 Loss: 0.000454\n",
      "2021-11-09 18:22:25.981863 Step: 2700 of 5656 Loss: 0.000388\n",
      "2021-11-09 18:22:32.210382 Step: 2800 of 5656 Loss: 0.000508\n",
      "2021-11-09 18:22:38.679880 Step: 2900 of 5656 Loss: 0.000434\n",
      "2021-11-09 18:22:44.634909 Step: 3000 of 5656 Loss: 0.000391\n",
      "2021-11-09 18:22:50.815135 Step: 3100 of 5656 Loss: 0.000447\n",
      "2021-11-09 18:22:56.839013 Step: 3200 of 5656 Loss: 0.000302\n",
      "2021-11-09 18:23:02.568905 Step: 3300 of 5656 Loss: 0.000728\n",
      "2021-11-09 18:23:08.789274 Step: 3400 of 5656 Loss: 0.000461\n",
      "2021-11-09 18:23:15.103072 Step: 3500 of 5656 Loss: 0.000448\n",
      "2021-11-09 18:23:21.421417 Step: 3600 of 5656 Loss: 0.000407\n",
      "2021-11-09 18:23:27.636784 Step: 3700 of 5656 Loss: 0.000570\n",
      "2021-11-09 18:23:33.879549 Step: 3800 of 5656 Loss: 0.000537\n",
      "2021-11-09 18:23:40.116353 Step: 3900 of 5656 Loss: 0.000785\n",
      "2021-11-09 18:23:46.457726 Step: 4000 of 5656 Loss: 0.000561\n",
      "2021-11-09 18:23:52.533244 Step: 4100 of 5656 Loss: 0.000255\n",
      "2021-11-09 18:23:58.134794 Step: 4200 of 5656 Loss: 0.000445\n",
      "2021-11-09 18:24:04.382778 Step: 4300 of 5656 Loss: 0.000598\n",
      "2021-11-09 18:24:10.734576 Step: 4400 of 5656 Loss: 0.000562\n",
      "2021-11-09 18:24:16.865103 Step: 4500 of 5656 Loss: 0.000498\n",
      "2021-11-09 18:24:23.051421 Step: 4600 of 5656 Loss: 0.000513\n",
      "2021-11-09 18:24:29.051508 Step: 4700 of 5656 Loss: 0.000498\n",
      "2021-11-09 18:24:35.286242 Step: 4800 of 5656 Loss: 0.000458\n",
      "2021-11-09 18:24:41.664780 Step: 4900 of 5656 Loss: 0.000592\n",
      "2021-11-09 18:24:47.869025 Step: 5000 of 5656 Loss: 0.000456\n",
      "2021-11-09 18:24:54.091607 Step: 5100 of 5656 Loss: 0.000490\n",
      "2021-11-09 18:25:00.374798 Step: 5200 of 5656 Loss: 0.000728\n",
      "2021-11-09 18:25:06.704620 Step: 5300 of 5656 Loss: 0.000521\n",
      "2021-11-09 18:25:12.759770 Step: 5400 of 5656 Loss: 0.000615\n",
      "2021-11-09 18:25:19.007897 Step: 5500 of 5656 Loss: 0.000371\n",
      "2021-11-09 18:25:25.382739 Step: 5600 of 5656 Loss: 0.000404\n",
      "Training Loss: 0.004960 for epoch 9\n",
      "Epoch:  9\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50745.\n",
      "accuracy:  96.36%; (non-O)\n",
      "accuracy:  96.76%; precision:  96.76%; recall:  96.76%; FB1:  96.76%\n",
      "             <e/>: precision:  96.07%; recall:  94.99%; FB1:  95.52%  3254\n",
      "             <f/>: precision:  97.58%; recall:  98.95%; FB1:  98.26%  38476\n",
      "             <i/>: precision:  88.86%; recall:  85.15%; FB1:  86.97%  413\n",
      "            <rm/>: precision:  86.13%; recall:  76.08%; FB1:  80.79%  591\n",
      "           <rms/>: precision:  91.60%; recall:  90.18%; FB1:  90.88%  1453\n",
      "            <rp/>: precision:  79.08%; recall:  46.06%; FB1:  58.21%  325\n",
      "           <rpn/>: precision:  86.56%; recall:  82.66%; FB1:  84.56%  1481\n",
      "        <rpnDel/>: precision:  58.33%; recall:  58.33%; FB1:  58.33%  84\n",
      "           <rps/>: precision:  83.01%; recall:  72.65%; FB1:  77.48%  512\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n",
      "Epoch: 100%|███████████████████████████████████| 10/10 [59:07<00:00, 354.78s/it]\n",
      "Total training time:  3547.7950318519725\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python bert_disf.py --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c487259-b5bc-4d90-b8f2-0508e0151e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-09 18:48:34.471913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-09 18:48:34.471936: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "test len:  366\n",
      "processed 52443 tokens with 52443 phrases; found: 52443 phrases; correct: 50745.\n",
      "accuracy:  96.36%; (non-O)\n",
      "accuracy:  96.76%; precision:  96.76%; recall:  96.76%; FB1:  96.76%\n",
      "             <e/>: precision:  96.07%; recall:  94.99%; FB1:  95.52%  3254\n",
      "             <f/>: precision:  97.58%; recall:  98.95%; FB1:  98.26%  38476\n",
      "             <i/>: precision:  88.86%; recall:  85.15%; FB1:  86.97%  413\n",
      "            <rm/>: precision:  86.13%; recall:  76.08%; FB1:  80.79%  591\n",
      "           <rms/>: precision:  91.60%; recall:  90.18%; FB1:  90.88%  1453\n",
      "            <rp/>: precision:  79.08%; recall:  46.06%; FB1:  58.21%  325\n",
      "           <rpn/>: precision:  86.56%; recall:  82.66%; FB1:  84.56%  1481\n",
      "        <rpnDel/>: precision:  58.33%; recall:  58.33%; FB1:  58.33%  84\n",
      "           <rps/>: precision:  83.01%; recall:  72.65%; FB1:  77.48%  512\n",
      "                O: precision: 100.00%; recall: 100.00%; FB1: 100.00%  5854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python bert_disf.py --mode test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bd5a4-2659-4398-96ee-a30c810c9c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
